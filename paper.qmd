---
title: "Making, Updating, and Querying Causal Models using `CausalQueries`"
format:
    jss-pdf:
        keep-tex: true
    jss-html: default
author:
  - name: Till Tietz
    affiliations:
      - name: WZB
        department: IPI
        address: Reichpietschufer 50
        city: Berlin
        country: Germany
        postal-code: 10785
    email: ttietz2014@gmail.com
    orcid: 0000-0002-2916-9059
    url: https://github.com/till-tietz
  - name: Lily Medina
    affiliations:
      - UC Berkeley
  - name: Macartan Humphreys
    affiliations:
      - WZB
    orcid: 0000-0001-7029-2326
    email: macartan.humphreys@wzb.eu
    url: https://macartan.github.io/
abstract: |
  A guide to the [R]{.proglang} package `CausalQueries`  for making, updating, and querying causal models

keywords: [causal models, stan, bayes]
keywords-formatted: [causal models, stan, bayes]

bibliography: bib.bib  
---

```{r, include = FALSE}
library(tidyverse)
library(CausalQueries)
library(knitr)
library(rstan)
library(DeclareDesign)

run <- FALSE
```

## Introduction: Causal models {#sec-intro}

### What CausalQueries does

`CausalQueries` is an [R]{.proglang} package that lets users make, update, and query causal models. The base specification asks users do provide a statement that reports a set of binary variables and the relations of causal ancestry between them: which variables are direct causes of other variables, given the other variables in the model. Once provided to `make_model()`, `CausalQueries` generates a set of parameters that fully describe all possible types of causal relations between variables ("causal types"), given the causal structure. Given a prior over distributions over causal types and data over some or all nodes, `update_model()` deploys a `stan` model in order to generate a posterior distribution over parameters. The function `query_model()` can then be used to ask any causal query of the model, using either the prior distribution, the posterior distribution, or a user specified candidate vector of parameters.   

We illustrate these three core functions by showing how to use `CuasalQueries` to replicate the analysis in @chickering1996clinician (see also @ii2023).   

@chickering1996clinician seek to draw inference on causal effects in the presence of imperfect compliance. We have access to an instrument $Z$ (a randomly assigned prescription for cholesterol medication), which is a cause of $X$ (treatment uptake) but otherwise unrelated to $Y$ (cholesterol). We imagine we are interested in three specific queries. The first is the average causal effect of $X$ on $Y$. The second is the average effect for units for which $X=0$ and $Y=0$. The last is the average treatment effect *for* "compliers": units for which $X$ responds positively to $Y$. Thus two of these are conditional queries, with one conditional on a counterfactual quantity.

Our data on $Z$, $X$, and $Y$ is complete for all units and looks, in compact form, as follows:

```{r}
data("chickering_pearl")

chickering_pearl |> kable()
```

Using `CausalQueries` we can define the model, update it with data, and query it, thus. 

```{r}  
results <- 
  
  make_model("Z -> X -> Y; X <-> Y") |>
  
  update_model(chickering_pearl, refresh = 0) |>
  
  query_model(query = "Y[X=1] - Y[X=0]",
              given = c("All",  "X==0 & Y==0", "X[Z=1] > X[Z=0]"),
              using = "posteriors") 
```

The output is a dataframe with estimates, posterior standard deviations, and credibility intervals. 

```{r, echo = FALSE}
results |>
  select(query, given, mean, sd, starts_with("cred")) |>
  kable(digits = 2, 
        caption = "Rows 1 and 2 replicate results in Chickering and Pearl (1997); row 3 returns inferences for complier average effects.")
```

As we describe below the same basic procedure of making, updating, and querying models, can be used (up to computational constraints) for arbitrary causal models, for different types of data structures, and for all causal queries that can be posed of the causal model.

### Software requirements

## Statistical model

The core conceptual framework is described in Pearl's *Causality* [@pearl2009causality] but can be summarized as follows (using the notation used in @ii2023). 

**Definition** A "**causal model**" is: 

  1. an ordered collection of "endogenous nodes" $Y = \{Y_1, Y_2, \dots, Y_n\}$
  2. an ordered collection of "exogenous nodes" $\Theta = \{\theta^{Y_1}, \theta^{Y_1}, \dots, \theta^{Y_n}\}$
  3. a collection of functions $F = \{f_{Y_1}, f_{Y_2}, \dots, f_{Y_n}\}$ specifying, for each node $j$, how outcome $y_j$ depends on $\theta_j$ and realizations of endogenous nodes prior to $j$.
  4. A probability distribution over $\Theta$, $\lambda$

In the usual case we take the endogenous nodes to be binary.^[`CausalQueries` can be used also to analyse non binary data though with a cost of greatly increased complexity. See section 9.4.1 of @ii2023 for an approach that codes non binary data in a profile of outcomes on multiple binary nodes.] When we specify a causal structure we specify which endogenous nodes are  (possibly) direct causes of a node, $Y_j$, given other nodes in the model. These nodes are called the parents of $Y_j$, $PA_j$ (we use upper case $PA_j$ to indicate the collection of nodes and lower case $pa_j$ to indicate a particular set of values that these nodes might take on). In this case, with discrete valued nodes, it is possible to identify all possible ways that a node might relate to its parents. We call these "nodal types," and they correspond to principal strata familiar, for instance, in the study of instrumental variables [@frangakis2002principal]. If node $Y_i$ can take on $k_i$ possible values then the set of possible values that can be taken on by parents of $j$ is $m :=\prod_{i\in PA_j}k_i$, then there are $k_j^{m}$ nodal types --- distinct ways that $k$ might respond to its parents---with each types corresponding to a distinct way that $j$ takes for a given constellation of values of its parents. In the case of binary nodes this becomes $2^{\left(2^{|PA_j|}\right)}$. Thus for an endogenous node with no parents there are 2 nodal types, for a binary node with one binary parent there are four types, for a binary node with 2 parents there are 16, and so on.

The set of all possible causal reactions of a given unit to all possible values of parents is then given by its collection of nodal types at each node. We call this collection a unit's "causal type", $\theta$.

The approach used by `CausalQueries` is to let the domain of $\theta^{Y_j}$ be coextensive with the number of nodal types for $Y_j$. Function $f^j$ then determines the value of $y$ by simply reporting the value of $Y_j$ implied by the nodal type and the values of the  parents of $Y_j$. Thus if $\theta^j_{pa_j}$ is the value for $j$ when parents have values $pa_j$, then we have simply that  $f_{y_j}(\theta^{j}, pa_j) = \theta^j_{pa_j}$. The practical implication is that, given the causal structure, learning about the model reduces to learning about the distribution $\lambda$ over the nodal types.

In cases in which there is no unobserved confounding, we take the probability distributions over the nodal types for different nodes to be independent: $\theta^i \perp\!\!\! \perp \theta^j, i\neq j$. In this case we use a categorical distribution to specify the ${\lambda^j}' := \Pr(\theta^j = {\theta^j}')$. From independence then we have that the probability of a given causal type $\theta'$ is simply $\prod_{i=1}^n {\lambda^i}'$.

In cases in which there is confounding, the essential logic is the same except that we need to specify enough parameters to capture the joint distribution over nodal types for different nodes. 

For concreteness: table illustrating all these values for a $X\rightarrow Y$ model

Representing beliefs over causal models thus requires specifying a probability distribution over $\lambda$. This might be  a degenerate distribution if users want to specify a particular model. `CausalQueries` allows users to specify parameters, $\alpha$ of a Dirichlet distribution over $\lambda$. If all entries of $\alpha$ are 0.5 this corresponds to Jeffrey's priors.  The default behavior is for  `CausalQueries`  to assume a uniform distribution -- that is, that all nodal types are equally likely -- which corresponds to $\alpha$ being a vector of 1s.

Updating is then done with respect to beliefs over $\lambda$. In the Bayesian approach we have simply:

$$p(\lambda'|D) = \frac{p(D|\lambda')p(\lambda)}{\int_{\lambda^{''}} p(D|\lambda'')p(\lambda'')}$$
$p(D|\lambda')$ is calculated  under the assumption that units are exchangeable and independently drawn, and of course, under the model.  In practice this means that the probability that two units have causal types  $\theta_i$ and $\theta_j$ is simply $\lambda'_i\lambda'_j$. Since a causal type fully determines an outcome vector $d = \{y_1, y_2,\dots,y_n\}$, the probability of a given outcome ("event"), $w_d$, is given simply by  the probability that the causal type is among those that yield  outcome $d$. Thus from $\lambda'$ we can calculate a vector of event probabilities, $w(\lambda)$, for each vector of outcomes, and under indpendence we have:

$$D \sim \text{Mulitimonial}(w(\lambda), N)$$

Thus for instance in the case of a $X \rightarrow Y$ model, and letting $w_{xy}$ denote the probability of a data type $X=x, Y=y$, the event probabilities are:

$$w(\lambda) = \left\{\begin{array}{ccc} w_{00} & = & \lambda^X_0(\lambda^Y_{00} + \lambda^Y_{01})\\ 
w_{01} & = & \lambda^X_0(\lambda^Y_{11} + \lambda^Y_{10})\\
w_{10} & = & \lambda^X_1(\lambda^Y_{00} + \lambda^Y_{10})\\
w_{11} & = & \lambda^X_1(\lambda^Y_{11} + \lambda^Y_{01})\end{array} \right.$$

* Embed the  *methods* and the *software* into the respective relevant literature. 
* For the latter both competing and complementary software should be discussed (within the same software environment and beyond), bringing out relative (dis)advantages. All software mentioned should be properly `@cited`'d. (See also [Using BibTeX] for more details on {{< bibtex >}}.)

### Connections to existing packages


-compare with bareinboim package
- knox bounds package


```{r, eval = FALSE, include = FALSE}
make_model("A -> B -> C -> D -> E")$parameters_df |> nrow()

make_model("A -> E <- B; C->E<-D")$parameters_df |> nrow()
```

The strength of `CausalQueries` is to allow users to specify arbitrary DAGs, arbitrary queries over nodes in those DAGs, and use the same canonical procedure to learn about those queries whether or not the queries are identified. Thus is principle if researchers are interest in learning about a quantitiy like the local average treatment effect and their model in fact satisfies the conditions in @angrist1996identification, then updating will recover valid estimates even if researchers are unaware that the local average treatment effect is identified and are ignorant of  the estimation procedure proposed by @angrist1996identification.    

There are two broad limitation on the sets of models handled natively by  `CausalQueries`. First `CausalQUeries` is designed for  models with a relatively small number  over binary nodes. Because there is no compromise made on the space of possible causal relations implied by a given model, the parameter space grows very rapidly with the complexity of the causal model.  The complexity also depends on the causal structure and grows rapidly with the number of parents affecting a given child. A chain model of the form $A \rightarrow B \rightarrow C \rightarrow D \rightarrow E$ has just 40 parameters. A model in which $A, B, C, D$  are all direct of $E$ has 65544 parameters. Moving from binary to non binary nodes has similar effects. The restriction to binary nodes is for computational and not conceptual reasons. In fact there are ways to employ `CausalQueries`  to answer queries from models with nonbinary nodes but in general the computational costs make analysis of these model prohibitive. 

Second the package is geared for learning about populations from samples of units that are independent of each other and are independently  randomly sampled  from populations. This the basic set up does not address problems of sampling, clustering,  hierarchical structures, or purposive sampling, for example. In section X we provide pointers to how all of these can be addressed.     




## Making models {#sec-models}

A model is defined in one step using a `dagitty` syntax in which the structure of the model is provided as a statement.

For instance:

```{r}
model <- make_model("X -> M -> Y <- X")
```

The statement (in quotes) provides the names of nodes. An arrow ("`->`" or "`<-`") connecting nodes indicates that one node is a potential cause of another  (that is, whether a given node is a "parent" or "child" of another. 

Formally a statement like this is interpreted as:

1. Functional equations:
  * $Y = f(M, X, \theta^Y)$
  * $M = f(X, \theta^M)$
  * $X = \theta^X$
  
2. Distributions on $\Theta$:
  * $\Pr(\theta^i = \theta^i_k) = \lambda^i_k$

3. Independence assumptions:   
* $\theta_i \perp\!\!\! \perp \theta_j, i\neq j$

where function $f$ maps from the set of possible values of the parents of $i$ to values of node $i$ given $\theta^i$ as described above.  

In addition, as we did in the @chickering1996clinician example, it is also possible to indicate "unobserved confounding", that is, the presence of an unobserved variable that might influence observed variables. In this case condition 3 above is relaxed. We describe how this is done in greater detail in section \@ref(confounding).


### Graphing

Once defined, a model can be graphed (we use the `dagitty` package for this):

```{r, fig.cap="A plotted model. Curved double headed arrows indicate unobserved confounding"}

model <- make_model("X -> Y <- W -> X; X <-> Y") |>
  plot()
```

This is useful to check that you have written the structure down correctly. 

### Model characterization

When a model is defined, a set of objects are generated. These are the key quantities that are used for all inference. 


#### Nodal types

Two units have the same *nodal type* at node $Y$, $\theta^Y$, if their outcome at $Y$ responds in the same ways to parents of $Y$. 

A node with $k$ parents has $2^{2^k}$ nodal types. The reason is that with $k$ parents, there are $2^k$ possible values of the parents and so  $2^{2^k}$ ways to respond to these possible parental values. As a convention we say that a node with no parents has two nodal types (0 or 1).

When a model is created the full set of "nodal types" is identified. These are stored in the model. The subscripts become very long and hard to parse for  more complex models so the model object also includes a guide to interpreting nodal type values. You can see them like this.

```{r, comment = ""}
make_model("X -> Y")$nodal_types
```


Note that we use $\theta^j$ to indicate nodal types because for qualitative analysis the nodal types are often the parameters of interest.

#### Causal types

Causal types are collections of nodal types. Two units are of the same *causal type* if they have the same nodal type at every node. For example in a $X \rightarrow M \rightarrow Y$ model, $\theta = (\theta^X_0, \theta^M_{01}, \theta^Y_{10})$ is a type that has $X=0$, $M$ responds positively to $X$, and $Y$ responds positively to $M$.

When a model is created, the full set of causal types is identified. These are stored in the model object:

```{r, comment = ""}
make_model("A -> B")$causal_types
```

A model with $n_j$ nodal types at node $j$ has $\prod_jn_j$ causal types. Thus the set of causal types can be large. In the model $(X\rightarrow M \rightarrow Y \leftarrow X)$ there are $2\times 4\times 16 = 128$ causal types.

Knowledge of a causal type tells you what values a unit would take, on all nodes, absent an intervention. For example for a model $X \rightarrow  M \rightarrow  Y$ a type $\theta = (\theta^X_0, \theta^M_{01}, \theta^Y_{10})$ would imply data $(X=0, M=0, Y=1)$. (The converse of this, of course, is the key to updating: observation of data $(X=0, M=0, Y=1)$ result in more weight placed on $\theta^X_0$, $\theta^M_{01}$, and $\theta^Y_{10})$.)

#### Parameters dataframe

When a model is created, `CausalQueries` attaches a "parameters dataframe" which keeps track of model parameters, which belong together in a family, and how they relate to causal types. This becomes especially important for more complex models with confounding that might involve more complicated mappings between parameters and nodal types. In the case with no confounding the nodal types *are* the parameters; in cases with confounding you generally have more parameters than nodal types.

For instance:

```{r, comment = ""}
make_model("X->Y")$parameters_df %>%
  kable()
```

Each row in the dataframe corresponds to a single parameter.

The columns of the parameters data frame are understood as follows:

* `param_names` gives the name of the parameter, in shorthand. For instance the parameter $\lambda^X_0 = \Pr(\theta^X = \theta^X_0)$ has `par_name`  `X.0`. See section \@ref(notation) for a summary of notation. 
* `param_value` gives the (possibly default) parameter values. These are probabilities.  
* `param_set` indicates which parameters group together to form a simplex. The parameters in a set have parameter values that sum to 1. In this example $\lambda^X_0 + \lambda^X_1 = 1$.
* `node`  indicates the node associated with the parameter. For parameter `\lambda^X_0` this is $X$.
* `nodal_type` indicates the nodal types associated with the parameter. 
* `gen`  indicates the place in the partial causal ordering (generation) of the  node associated with the parameter
* `priors` gives (possibly default) Dirichlet priors arguments for parameters in a set. Values of 1 (.5) for all parameters in a set implies uniform (Jeffrey's) priors over this set. 

Below we will see examples where the parameter dataframe helps keep track of parameters that are created when confounding is added to a model. 

#### Parameter matrix

The parameters dataframe keeps track of parameter values and priors for parameters but it does not provide a mapping between parameters and the probability of causal types.

The parameter matrix  ($P$  matrix) can be added to the model to provide this mapping. The $P$ matrix has a row for each parameter and a column for each causal type. For instance:

```{r, comment = ""}
make_model("X->Y") %>% get_parameter_matrix %>%
  kable
```

The probability of a causal type is given by the product of the parameters values for parameters whose row in the $P$ matrix contains a 1.  

Below we will see examples where the $P$ matrix helps keep track of parameters that are created when confounding is added to a model. 

### Tailoring models

#### Setting restrictions {#restrictions}

When a model is defined, the complete set of possible causal relations are worked out. This set can be very large. 

Sometimes for theoretical or practical reasons it is useful to constrain the set of types. In `CausalQueries` this is done at the level of nodal types, with restrictions on causal types following from restrictions on nodal types.

For instance to impose an assumption that $Y$ is not decreasing in $X$ we generate a restricted model as follows:

```{r}
model <- make_model("X->Y") %>% set_restrictions("Y[X=1] < Y[X=0]")
```

or:


```{r}
model <- make_model("X->Y") %>% set_restrictions(decreasing("X", "Y"))
```


Viewing the resulting parameter matrix we see that both the set of parameters and the set of causal types are now restricted:

```{r, comment = ""}
get_parameter_matrix(model)
```

Here and in general, setting restrictions typically involves using causal syntax;  see Section \@ref(syntax) for a guide the syntax used by `CausalQueries`.

Note:

* Restrictions have to operate on nodal types: restrictions on *levels* of endogenous nodes aren't allowed. This, for example, will fail: 
`make_model("X->Y") %>% set_restrictions(statement =  "(Y == 1)")`. The reason is that it requests a correlated restriction on nodal types for `X` and `Y` which involves undeclared confounding. 
* Restrictions implicitly assume fixed values for *all* parents of a node. For instance: `make_model("A -> B <- C") %>% set_restrictions("(B[C=1]==1)")` is interpreted as shorthand for the restriction  `"B[C = 1, A = 0]==1 | B[C = 1, A = 1]==1"`.
* To place restrictions on multiple nodes at the same time, provide these as a vector of restrictions. This is not permitted: `set_restrictions("Y[X=1]==1 & X==1")`, since it requests correlated restrictions. This however is allowed: `set_restrictions(c("Y[X=1]==1", "X==1"))`.  
* Use the `keep` argument to indicate whether nodal types should be dropped (default) or retained.
* Restrictions can be set using nodal type labels. `make_model("S -> C -> Y <- R <- X; X -> C -> R") %>%
set_restrictions(labels = list(C = "C1000", R = "R0001", Y = "Y0001"), keep = TRUE)`
* Wild cards can be used in nodal type labels: `make_model("X->Y") %>%
set_restrictions(labels = list(Y = "Y?0"))`

### Allowing confounding {#confounding}

(Unobserved) confounding between two nodes arises when the nodal types for the nodes are not independently distributed. 

In the $X \rightarrow Y$ graph, for instance, there are 2 nodal types for $X$ and 4 for $Y$. There are thus 8 joint nodal types (or causal types):

|   |    | $\theta^X$         |                    |           |
|:-:|:--:|:------------------:|:-------------------|-----------|
|   |  | 0                    | 1                  | Sum       |
|$\theta^Y$ | 00 | $\Pr(\theta^X_0, \theta^Y_{00})$ | $\Pr(\theta^X_1, \theta^Y_{00})$ | $\Pr(\theta^Y_{00})$|
|   | 10 | $\Pr(\theta^X_0, \theta^Y_{10})$ | $\Pr(\theta^X_1, \theta^Y_{10})$ | $\Pr(\theta^Y_{10})$|
|   | 01 | $\Pr(\theta^X_0, \theta^Y_{01})$ | $\Pr(\theta^X_1, \theta^Y_{01})$ | $\Pr(\theta^Y_{01})$|
|   | 11 | $\Pr(\theta^X_0, \theta^Y_{11})$ | $\Pr(\theta^X_1, \theta^Y_{11})$ | $\Pr(\theta^Y_{11})$|
|   |Sum | $\Pr(\theta^X_0)$  | $\Pr(\theta^X_1)$  | 1         |

This table has 8 interior elements and so an unconstrained joint distribution would have 7 degrees of freedom. A no confounding assumption means that $\Pr(\theta^X | \theta^Y) = \Pr(\theta^X)$, or $\Pr(\theta^X, \theta^Y) = \Pr(\theta^X)\Pr(\theta^Y)$. In this case we just put a distribution on the marginals and there would be 3 degrees of freedom for $Y$ and 1 for $X$, totaling $4$ rather than 7.


```{r, comment  = ""}
confounded <- make_model("X->Y ; X <-> Y")

confounded$parameters_df %>% kable

```

We see here that there are now two parameter families for parameters associated with the node $Y$. Each family captures the conditional distribution of $Y$'s nodal types, given $X$. For instance the parameter `Y01_X.1` can be interpreted as $\Pr(\theta^Y = \theta^Y _{01} | X=1)$.

To see exactly how the parameters map to causal types we can view the parameter matrix:

```{r, comment = ""}
get_parameter_matrix(confounded) %>% kable()
```

Importantly, the $P$ matrix works as before, despite confounding. We can assess the probability of causal types by multiplying the probabilities of the constituent parameters.


* Unlike nodal restrictions, a confounding relation can involve multiple nodal types simultaneously. For instance `make_model("X -> M -> Y") %>% set_confound(list(X = "Y[X=1] > Y[X=0]"))` allows for a parameter that renders $X$ more or less likely depending on whether $X$ has a positive effect on $Y$ whether it runs through a positive or a negative effect on $M$.
* The parameters needed to capture confounding relations depend on the direction of causal arrows. For example compare:
  * `make_model("A -> W <- B ; A <-> W; B <-> W")$parameters_df %>% dim`   In this case we can decompose shocks on $A, B, W$ via: $\Pr(\theta^A, \theta^B,  \theta^W) = \Pr(\theta^W | \theta^A, \theta^A)\Pr(\theta^A)\Pr(\theta^B)$, and we have 68 parameters. 
  * `make_model("A <- W -> B ; A <-> W; B <-> W")$parameters_df %>% dim` In this case we have $\Pr(\theta^A, \theta^B,  \theta^W) = \Pr(\theta^A | \theta^W)\Pr(\theta^B|\theta^W)\Pr(\theta^W)$ and just has just 18 parameters.

When confounding is added to a model, a dataframe, `confounds_df` is created and added to the model, recording which variables involve confounding. This is then used for plotting:

```{r}
make_model("A <- X -> B; A <-> X; B <-> X") %>% plot()
```

#### Setting Priors {#priors}

Priors on model parameters can be added to the parameters dataframe. The priors are interpreted as alpha arguments for a Dirichlet distribution. They can be seen using `get_priors`.

```{r, comment = ""}

make_model("X->Y") %>% get_priors

```

Here the priors have not been specified and so they default to 1, which corresponds to uniform priors.

Alternatively you could set jeffreys priors like this:

```{r, comment = ""}

make_model("X->Y") %>% set_priors(distribution = "jeffreys") %>% get_priors

```

Custom priors are most simply specified by being added as a vector of numbers using `set_priors`. For instance:

```{r, comment = ""}

make_model("X->Y") %>% set_priors(1:6) %>% get_priors

```

The priors here should be interpreted as indicating:

 * $\alpha_X = (1,2)$, which implies a distribution over $(\lambda^X_0, \lambda^X_1)$ centered on $(1/3, 2/3)$. 
 * $\alpha_Y = (3,4,5,6)$, which implies a distribution over $(\lambda^Y_{00}, \lambda^Y_{10}, \lambda^Y_{01} \lambda^Y_{11})$ centered on $(3/18, 4/18, 5/18, 6/18)$. 

For larger models it can be hard to provide priors as a vector of numbers and so `set_priors` can allow for more targeted modifications of the parameter vector. For instance:

```{r, comment = ""}
make_model("X->Y") %>%
  set_priors(statement = "Y[X=1] > Y[X=0]", alphas = 3) %>%
  get_priors
```

See `?set_priors` and `?make_priors` for many examples.


We note that flat priors over nodal types does not necessarily translate into flat priors over queres. "Flat" priors over parameters in a parameter family put equal weight on each nodal type, but this in turn can translate into strong assumptions on causal quantities of interest. 

For instance in an $X \rightarrow Y$ model model in which negative effects are ruled out, the average causal effect implied by "flat" priors is $1/3$. This can be seen by querying the model:

```{r}

make_model("X -> Y") %>%
  set_restrictions(decreasing("X", "Y")) %>%
  query_model("Y[X=1] - Y[X=0]", n_draws = 10000) %>%
  kable(digits = 2)

```

More subtly the *structure* of a model, coupled with flat priors, has substantive importance for priors on causal quantities. For instance with flat priors, priors on the probability that $X$ has a positive effect on $Y$ in the model $X \rightarrow Y$ is centered on $1/4$. But priors on the probability that $X$ has a positive effect on $Y$ in the model $X \rightarrow M \rightarrow Y$ is centered on $1/8$. 

Again, you can use `query_model` to figure out what flat  (or other) priors over parameters imply for priors over causal quantities:

```{r}

make_model("X -> Y") %>%
  query_model("Y[X=1] > Y[X=0]", n_draws = 10000) %>%
  kable

make_model("X -> M -> Y") %>%
  query_model("Y[X=1] > Y[X=0]", n_draws = 10000) %>%
  kable

```


Caution regarding priors is particularly important when models are not identified, as is the case for many of the models considered here. In such cases, for some quantities, the marginal posterior distribution can be the same as the marginal prior distribution [@poirier1998revising].

The key point here is to make sure you do not fall into a trap of thinking that "uninformative" priors make no commitments regarding the values of causal quantities of interest. They do, and the implications of flat priors for causal quantities can depend on the structure of the model. Moreover for some inferences from causal models the priors can matter a lot even if you have a lot of data. In such cases it can be helpful to know what priors on parameters imply for priors on causal quantities of interest  (by using `query_model`) and to assess how much conclusions depend on priors (by comparing results across models that vary in their priors).


#### Setting Parameters {#parameters}

By default, models have a vector of parameter values included in the `parameters_df` dataframe. These are useful for generating data, or for situations, such as process tracing, when one wants to make inferences about causal types ($\theta$), given case level data, under the assumption that the model is known. 

Consider the causal model below. It has two parameter sets, X and Y, with six nodal types, two corresponding to X and four corresponding to Y. The key feature of the parameters is that they must sum to 1 within each parameter set. 

```{r, comment = ""}

make_model("X->Y") |> 
  get_parameters()

```

Setting parameters can be done using a similar syntax as `set_priors`. The main difference is that when a given value is altered the entire set must still always sum to 1. The example below illustrates a change in the value of the parameter $Y$ in the case it is increasing in $X$. Here nodal type `Y.Y01` is set to be .5, while the other nodal types of this parameter set were renormalized so that the parameters in the set still sum to one.

```{r, comment = ""}
make_model("X->Y") %>%
  set_parameters(statement = "Y[X=1] > Y[X=0]", parameters = .5) %>%
  get_parameters
```





###  Using models


#### Drawing data

```{r, eval = TRUE}
model |> make_data(n = 5) |> kable()

```

## Updating models

The approach used by the `CausalQueries` package to updating parameter values given observed data uses `stan` and involves the following elements:

* Dirichlet priors over parameters, $\lambda$ (which, in cases without confounding, correspond to nodal types)
* A mapping from parameters to event probabilities, $w$
* A likelihood function that assumes events are distributed according to a multinomial distribution given event probabilities. 

We provide further details below. 

### Data for stan 

We use a generic `stan` model that works for all binary causal models. Rather than writing a new `stan` model for each causal model we send `stan` details of each particular causal model as data inputs. 

In particular we provide a set of matrices that `stan` tailor itself to  particular models: the parameter matrix ($P$ ) tells `stan` how many parameters there are, and how they map into causal types; an ambiguity matrix $A$ tells `stan` how causal types map into data types; and an event matrix $E$ relates data types into patterns of observed data (in cases where there are incomplete observations). 

The internal function `prep_stan_data` prepares data for `stan`. You generally don't need to use this manually, but we show here a sample of what it produces as input for `stan`.

We provide  `prep_stan_data` with data in compact form (listing "data events").

```{r ch2compact, comment = ""}
model <- make_model("X->Y")

data  <- data.frame(X = c(0, 1, 1, NA), Y = c(0, 1, 0, 1)) 

compact_data <-  collapse_data(data, model) 

kable(compact_data)
```

Note that NAs are interpreted as data not having been sought. So in this case the interpretation is that there are two data strategies: data on $Y$ and $X$ was  sought in three cases; data on  $Y$ only was sought in just one case. 

`prep_stan_data` then returns a list of objects that `stan` expects to receive. These include indicators to figure out where a parameter set starts (`l_starts`, `l_ends`) and ends and where a data strategy starts and ends (`strategy_starts`, `strategy_ends`), as well as the matrices described above.

```{r ch2prep, comment = "", include = FALSE}

CausalQueries:::prep_stan_data(model, compact_data)

```


### stan code

Below we show the  `stan` code. This starts off with a block saying what input data is to be expected. Then there is a characterization of parameters and the transformed parameters. Then the likelihoods and priors are provided. `stan` takes it from there and generates a posterior distribution.

```{r, echo = FALSE, comment = ""}
 if(run) 
   update_model(make_model("X->Y"), data = data,
                keep_fit = TRUE)$stan_objects$stan_fit %>%
   write_rds("saved/fit.rds")
  
cat(rstan::get_stancode(read_rds("saved/fit.rds")))



```


The `stan` model works as follows:

* We are interested in "sets" of parameters. For example in the $X \rightarrow Y$ model we have two parameter sets (`param_sets`). The first is $\lambda^X \in \{\lambda^X_0, \lambda^X_1\}$ whose elements give the probability that $X$ is 0 or 1. These two probabilities sum to one. The second parameter set  is $\lambda^Y \in \{\lambda^Y_{00}, \lambda^Y_{10}, \lambda^Y_{01} \lambda^Y_{11}\}$. These are also probabilities and their values sum to one. Note in all that we have 6 parameters but just 1 + 3 = 4 degrees of freedom. 
* We would like to express priors over these parameters using multiple Dirichlet distributions (two in this case). In practice because we are dealing with multiple simplices of varying length, it is easier to express priors over gamma distributions with a unit scale parameter and shape parameter corresponding to the Dirichlet priors, $\alpha$. We make use of the fact that $\lambda^X_0 \sim Gamma(\alpha^X_0,1)$ and $\lambda^X_1 \sim Gamma(\alpha^X_1,1)$ then $\frac{1}{\lambda^X_0 +\lambda^X_1}(\lambda^X_0, \lambda^X_1) \sim Dirichlet(\alpha^X_0, \alpha^X_1)$. For a discussion of implementation of this approach in `stan` see https://discourse.mc-stan.org/t/ragged-array-of-simplexes/1382.
* For any candidate parameter vector $\lambda$ we calculate the probability of *causal* types (`prob_of_types`) by taking, for each type $i$, the product of the probabilities of all parameters ($\lambda_j$) that appear in column $i$ of the parameter matrix $P$. Thus the probability of a $(X_0,Y_{00})$ case is just $\lambda^X_0 \times \lambda^Y_{00}$. The implementations in `stan` uses `prob_of_types_[i]` $= \prod_j \left(P_{j,i} \lambda_j + (1-P_{j,i})\right)$: this multiplies the probability of all parameters involved in the causal type (and substitutes 1s for parameters that are not). (`P` and `not_P` (1-$P$) are provided as data to `stan`).

* The probability of data types, `w`, is given by summing up the probabilities of all  causal types that produce a given data type. For example, the probability of a $X=0,Y=0$ case, $w_{00}$ is   $\lambda^X_0\times \lambda^Y_{00} + \lambda^X_0\times \lambda^Y_{01}$. The ambiguity matrix $A$ is provided to `stan` to indicate which probabilities need to be summed.
* In the case of incomplete data we first identify the set of "data strategies", where a collection of a data strategy might be of the form "gather data on $X$ and $M$, but not $Y$,  for $n_1$ cases and gather data on $X$ and $Y$, but not $M$, for $n_2$ cases. The probability of an observed event, within a data strategy, is given by summing the probabilities of the types that could give rise to the incomplete data. For example $X$ is observed, but $Y$ is not, then the probability of $X=0, Y = \text{NA}$ is $w_{00} +w_{01}$. The matrix $E$ is passed to `stan` to figure out which event probabilities need to be combined for events with missing data.
* The probability of a dataset is then given by a multinomial distribution with these event probabilities (or, in the case of incomplete data, the product of multinomials, one for each data strategy). Justification for this approach relies on the likelihood principle and is discussed in Chapter 6.   


### Implementation

To update a CausalQueries model with data use:

```{r, eval = FALSE}
update_model(model, data)
```

where the data argument is a dataset containing some or all of the nodes in the model.

As `update_model()` calls `rstan::sampling` one can pass along all arguments in `...` to `rstan::sampling`. For instance:

* `iter` sets the number of iterations and ultimately the number of draws in the posterior
* `chains` sets the number of chains; doing multiple chains in parallel speeds things up

If you have multiple cores you can do parallel processing by including this line before running `CausalQueries`:

```{r, eval = FALSE}
options(mc.cores = parallel::detectCores())
```




Note the parameters estimated by `stan` include the gamma parameters plus transformed parameters, $\lambda$, which are our parameters of interest and which `CausalQueries` then interprets as possible row probabilities for the $P$ matrix. 





### censored data

### Output

The primary output from `update_model()` is a posterior distribution over model parameters, stored as a dataframe in `model$posterior_distribution`. However another of other objects are also optionally stored:


## Querying models 

Models can be queried using the `query_distribution` and `query_model` functions. The difference between these functions is that `query_distribution` examines a single query and returns a full distribution of draws from the distribution of the estimand (prior or posterior); `query_model` takes a collection of queries and returns a dataframe with summary statistics on the queries. 

The simplest queries ask about causal estimands given particular parameter values and case level data. Here is one surprising result of this form:

### Case level queries

The `query_model` function takes causal queries and conditions (`given`) and specifies the parameters to be used. The result is a dataframe which can be displayed as a table.

For a case level query we can make the query *given* a particular parameter vector, as below: 

```{r}
make_model("X-> M -> Y <- X") %>% 
  
  set_restrictions(c(decreasing("X", "M"), 
                     decreasing("M", "Y"), 
                     decreasing("X", "Y"))) %>%
  
  query_model(queries = "Y[X=1]> Y[X=0]",
              given = c("X==1 & Y==1", 
                        "X==1 & Y==1 & M==1", 
                        "X==1 & Y==1 & M==0"),
              using = c("parameters")) %>%
  
  kable(
    caption = "In a monotonic model with flat priors, knowledge
    that $M=1$ *reduces* confidence that $X=1$ caused $Y=1$")

```

This example shows how inferences change given additional data on $M$ in a monotonic $X \rightarrow M \rightarrow  Y \leftarrow  X$ model. Surprisingly observing $M=1$ *reduces* beliefs that $X$ caused $Y$, the reason being that perhaps $M$ and not $X$ was responsible for $Y=1$.

### Posterior queries

Queries can also draw directly from the posterior distribution provided by `stan`. In this next example we illustrate the joint distribution of the posterior over causal effects, drawing directly from the posterior dataframe generated by `update_model`:

```{r, warning = FALSE, eval = FALSE}
library(DeclareDesign)

data  <- fabricate(N = 100, X = complete_ra(N), Y = X)

model <- make_model("X -> Y; X <-> Y") %>%
  update_model(data, iter  = 4000)

model$posterior_distribution %>% 
  data.frame() %>%
  ggplot(aes(X.1 - X.0, Y.01_X.1 - Y.10_X.0)) + 
  geom_point()

```


```{r, warning = FALSE, echo = FALSE}

if(run){
data  <- fabricate(N = 100, X = complete_ra(N), Y = X)

model <- make_model("X->Y; X<->Y") %>% 
  update_model(data, iter  = 4000)

write_rds(model, "saved/app_2_illus.rds")
}

model <- read_rds("saved/app_2_illus.rds")

model$posterior_distribution %>% 
  data.frame() %>%
  ggplot(aes(X.1 - X.0, Y.01_X.1 - Y.10_X.0)) + 
  geom_point()

```

We see that beliefs about the size of the overall effect are related to beliefs that $X$ is assigned differently when there is a positive effect.

### Query distribution

`query_distribution` works similarly except that the query is over an estimand. For instance:

```{r, fig.cap = "Prior on 'Probability $Y$ is increasing in $X$'"}
make_model("X -> Y") %>% 
  query_distribution(
    query = list(increasing = "(Y[X=1] > Y[X=0])"), 
    using = "priors") |>
  ggplot(aes(increasing)) +
  geom_histogram()
  


```

### Token and general causation

Note that in all these cases we use the same technology to make case level and population inferences. Indeed the case level query is just a conditional population query. As an illustration of this imagine we have a model of the form $X \rightarrow M \rightarrow Y$ and are interested in whether $X$ caused $Y$ in a case in which $M=1$. We answer the question by asking "what would be the probability that $X$ caused $Y$ in a case in which $X=M=Y=1$?" (line 3 below). This speculative answer is the same answer as we would get were we to ask the same question having updated our model with knowledge that in a particular case, indeed, $X=M=Y=1$. See below: 


```{r, eval = FALSE}

model <- make_model("X->M->Y") %>% 
  set_restrictions(c(decreasing("X", "M"), decreasing("M", "Y"))) %>%
  update_model(data = data.frame(X = 1, M = 1, Y = 1), iter = 8000)

query_model(
            model, 
            query = "Y[X=1]> Y[X=0]",
            given = c("X==1 & Y==1", "X==1 & Y==1 & M==1"),
            using = c("priors", "posteriors"),
            expand_grid = TRUE)


```


```{r, echo = FALSE}

if(run){
model <- make_model("X->M->Y") %>% 
  set_restrictions(c(decreasing("X", "M"), decreasing("M", "Y"))) %>%
  update_model(data = data.frame(X = 1, M = 1, Y = 1), iter = 12000, chains = 8)

query <- query_model(
            model, 
            query = "Y[X=1]> Y[X=0]",
            given = c("X==1 & Y==1", "X==1 & Y==1 & M==1"),
            using = c("priors", "posteriors"),
            expand_grid = TRUE)

write_rds(query, "saved/app_ch2_demonsx.rds")
}

query <- read_rds("saved/app_ch2_demonsx.rds")

kable(query, caption = "Posteriors equal priors for a query that conditions on data used to form the posterior ", digits = 2)

```

We see the conditional inference is the same using the prior and the posterior distributions. 




## Computational details {.unnumbered}

* information about certain computational details such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, …) that are not cited in the main text can be credited here.

:::

The results in this paper were obtained using [R]{.proglang}~3.4.1 with the
[MASS]{.pkg}~7.3.47 package. [R]{.proglang} itself and all packages used are available from the Comprehensive [R]{.proglang} Archive Network (CRAN) at
[https://CRAN.R-project.org/].


## Acknowledgments {.unnumbered}

:::{.callout}

The approach to generating a generic stan function that can take data from arbitrary models was developed in key contributions by [Jasper Cooper](http://jasper-cooper.com/) and [Georgiy Syunyaev](http://gsyunyaev.com/). [Lily Medina](https://lilymedina.github.io/) did magical work pulling it all together and developing approaches to characterizing confounding and defining estimands. Clara Bicalho helped figure out the syntax for causal statements. Julio Solis made many key contributions figuring out how to simplify the specification of priors. Merlin Heidemanns figure out the `rstantools` integration and made myriad code improvements. Till Tietz revamped the entire package and improved every part of it.



:::

## References {.unnumbered}

:::{#refs}

:::

{{< pagebreak >}}

## More technical details {#sec-techdetails .unnumbered}

:::{.callout}

Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just _Appendix_).

For more technical style details, please check out JSS's style FAQ at
[https://www.jstatsoft.org/pages/view/style#frequently-asked-questions]
which includes the following topics:

- Title vs. sentence case.
- Graphics formatting.
- Naming conventions.
- Turning JSS manuscripts into [R]{.proglang} package vignettes.
- Trouble shooting.
- Many other potentially helpful details…

:::

## Using BibTeX {#sec-bibtex .unnumbered}

:::{.callout}

References need to be provided in a {{< bibtex >}} file (`.bib`). All
references should be made with `@cite` syntax. This commands yield different
formats of author-year citations and allow to include additional details (e.g.,pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up {{< bibtex >}} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.

- item JSS-specific markup (`\proglang`, `\pkg`, `\code`) should be used in the references.
- item Titles should be in title case.
- item Journal titles should not be abbreviated and in title case.
- item DOIs should be included where available.
- item Software should be properly cited as well. For [R]{.proglang} packages `citation("pkgname")` typically provides a good starting point.

:::


